# 医療AIワークフローガイド：倫理審査申請書類作成支援

## イントロダクション

医療AIの研究開発において、倫理審査委員会（IRB）への申請は避けて通れない重要なプロセスです。しかし、申請書類の作成は、専門的な内容に加え、倫理的・法的・社会的課題（ELSI）への深い理解と、厳密な文書作成能力が求められるため、研究者にとって大きな負担となっています。

本ガイドは、大規模言語モデル（LLM）を活用し、この複雑で時間のかかる倫理審査申請書類の作成を効率化し、その質を向上させるための具体的なワークフローを提供します。AIを「倫理文書作成の専門家」として活用することで、研究者はより本質的な研究内容の検討に集中できるようになります。

---

## 倫理審査申請プロセスの全体フロー

AIを活用した倫理審査申請のワークフローを視覚的に理解しましょう。

![個理審査申請プロセス](/Helix/assets/guides/ethics-review-application/review_workflow.png)

---

## 基本編：研究の倫理的基盤の構築（2ステップ）

基本編では、倫理審査申請の核となる「研究計画の骨子」と「倫理的配慮事項」をAIと共に明確化します。

### ステップ1：研究計画の骨子作成

倫理審査申請書で最も重要なのは、研究の目的、方法、対象が明確であることです。AIにこれらの情報を整理させ、申請書の主要なセクションの骨子を生成します。

| 項目 | 詳細 |
| :--- | :--- |
| 目的 | 申請書の核となる研究の概要、目的、方法論を明確にする。 |
| プロンプト例 | `あなたは医療AI研究の倫理審査申請書作成の専門家です。以下の情報に基づき、「研究の目的」と「研究方法の概要」の骨子を、審査員が理解しやすいように箇条書きで作成してください。\n\n【研究情報】\n・テーマ: 〇〇を用いた△△疾患の早期診断AIの開発\n・対象: 20XX年～20YY年に当院を受診した△△疾患患者の匿名化された電子カルテデータ（N=5000）\n・期間: 20ZZ年4月1日～20AA年3月31日\n・AI利用の概要: 畳み込みニューラルネットワーク（CNN）を用いて、画像データから疾患の特徴量を抽出し、診断支援を行う。` |
| AIの出力例 | 【研究の目的（骨子）】\n1. 既存の診断手法と比較し、AIモデルの診断精度（感度、特異度）を評価する。\n2. 早期段階での△△疾患の検出を可能にし、患者の予後改善に貢献する。\n3. 医療現場でのAI導入に向けた技術的・倫理的課題を特定し、解決策を提案する。\n\n【研究方法の概要（骨子）】\n1. データ収集: 匿名化された電子カルテデータ（画像、検査値、診断名）を研究倫理委員会の承認に基づき収集する。\n2. データ前処理: 画像データの正規化、欠損値の補完、データセットの分割（学習、検証、テスト）を実施する。\n3. AIモデル構築: CNNアーキテクチャ（例: ResNet-50）を採用し、収集データで学習を行う。\n4. 評価: 独立したテストデータセットを用いて、ROC曲線、AUCなどの指標でモデル性能を評価する。 |
| まとめ | AIに研究の全体像を構造化させることで、申請書作成の方向性が定まり、後の詳細記述がスムーズになります。 |

### ステップ2：倫理的配慮事項の洗い出し

医療AI研究は、特に個人情報保護やAIの公平性に関して、特有の倫理的課題を伴います。AIに研究計画から想定されるELSIを網羅的にリストアップさせ、対応策のヒントを得ます。

| 項目 | 詳細 |
| :--- | :--- |
| 目的 | AI利用に伴う主要な倫理的課題（データプライバシー、バイアス、インフォームド・コンセントなど）をリストアップする。 |
| プロンプト例 | `ステップ1で作成した研究計画の骨子を再確認し、この研究で特に重要となる倫理的・法的・社会的課題（ELSI）を3点以上挙げ、それぞれに対する具体的な対応策の提案を記述してください。特に「匿名加工情報」と「AIのバイアス」に焦点を当ててください。` |
| AIの出力例 | 1. 個人情報の保護と匿名加工情報の取り扱い\n- 課題: 匿名化されたデータを使用するが、再識別化のリスクはゼロではない。\n- 対応策: データの匿名化レベルを専門家が確認し、匿名加工情報作成ガイドラインに厳密に準拠する。データアクセス権限を研究責任者およびデータ管理者に限定し、厳重なセキュリティ下で管理する。\n\n2. AIモデルにおけるバイアスの可能性\n- 課題: 特定の人種、性別、年齢層のデータが不足している場合、AIモデルが公平な診断結果を提供できない可能性がある。\n- 対応策: データセットの属性（性別、年齢、人種など）の分布を詳細に分析し、偏りがある場合はサンプリング手法や重み付けにより是正を試みる。バイアス評価指標（例: 均等なオッズ）を用いてモデルを評価し、結果を申請書に明記する。\n\n3. 研究結果の医療現場への還元と責任の所在\n- 課題: 開発したAIが誤った診断を下した場合の責任の所在が不明確になる可能性がある。\n- 対応策: AIはあくまで「診断支援」ツールであり、最終的な診断と治療方針の決定は医師が行うことを明確にする。この点をインフォームド・コンセント文書にも明記する。 |
| まとめ | AIによる網羅的なELSIの洗い出しは、研究者が盲点となりがちな倫理的リスクを事前に特定し、適切な対応策を講じる上で極めて有効です。 |

---

## 実践編：申請書項目の詳細記述と調整（3ステップ）

実践編では、基本編で作成した骨子と倫理的配慮事項を基に、申請書の具体的な記述を生成し、審査に耐えうるレベルに文章を調整します。

### ステップ3：申請書項目の詳細記述

倫理審査申請書は、各項目について具体的かつ詳細な記述を求めます。AIに特定の項目（例：データ管理計画）の記述を生成させます。

| 項目 | 詳細 |
| :--- | :--- |
| 目的 | 倫理審査申請書の具体的な項目について、詳細な記述を生成する。 |
| プロンプト例 | `以下の研究計画と倫理的配慮事項に基づき、「研究に使用するデータの管理計画」について、倫理審査委員会向けに詳細な文章を作成してください。特に、データの匿名化、保管場所、アクセス権限、研究終了後の取り扱いについて具体的に記述すること。\n\n【研究計画と配慮事項（ステップ1, 2の出力内容を引用）】` |
| AIの出力例 | 研究に使用するデータの管理計画\n\n本研究で使用するデータは、すべて連結不可能匿名化された電子カルテ情報（画像、検査値、診断名）であり、個人を特定できる情報は含まれておりません。データの取り扱いは、「人を対象とする生命科学・医学系研究に関する倫理指針」および当院の個人情報保護規定に厳密に準拠します。\n\n1. 保管場所: 匿名化されたデータは、外部ネットワークから完全に隔離された研究部門内のセキュアサーバー（アクセスログ取得機能付き）に保管されます。\n2. アクセス権限: データへのアクセス権限は、研究責任者およびデータ管理担当者（計2名）に限定され、パスワードによる二段階認証を必須とします。\n3. 研究終了後の取り扱い: 研究期間終了後、データは原則として完全に消去します。ただし、将来的な追跡研究の可能性を考慮し、研究責任者の判断により、倫理委員会の再承認を得た上で、さらに厳重な管理下で保管を継続する場合があります。 |
| まとめ | AIは、必要な要素（匿名化、保管、アクセス、消去）を網羅した、形式的に正しい記述を迅速に生成できます。 |

### ステップ4：専門用語の統一と表現の調整

申請書は、曖昧な表現や専門用語の不統一があると、審査員に誤解を与える可能性があります。AIに文章の客観性と厳密性を高める調整を依頼します。

| 項目 | 詳細 |
| :--- | :--- |
| 目的 | 申請書全体で用語の統一を図り、審査員に理解されやすい、正確で客観的な表現に調整する。 |
| プロンプト例 | `以下の文章を、倫理審査委員会の委員が理解しやすいように、専門用語を統一し、客観的かつ厳密な表現に修正してください。特に「ディープラーニング」という用語を「深層学習」に統一し、「たぶん」や「～と思われる」といった曖昧な表現を排除してください。\n\n【修正対象の文章】\n「このディープラーニングモデルは、たぶん、従来の統計モデルよりも高い精度を出すと思われる。患者さんへの説明は、口頭で十分だと思う。」` |
| AIの出力例 | 【修正後の文章】\n「本研究で用いる深層学習モデルは、従来の統計モデルと比較して、客観的な評価指標に基づき高い診断精度を示すことが期待されます。患者への研究説明は、口頭での説明に加え、文書による同意取得を必須とし、倫理指針に則り実施します。」 |
| まとめ | AIによる表現の調整は、申請書のプロフェッショナリズムを高め、審査員からの信頼性を向上させる上で不可欠です。 |

### ステップ5：利益相反（COI）に関する記述の作成

研究の透明性を確保するため、利益相反（COI）に関する適切な開示は必須です。AIに規定に基づいた開示文案を作成させます。

| 項目 | 詳細 |
| :--- | :--- |
| 目的 | 研究に関わる利益相反の有無と、ある場合の適切な開示文を作成する。 |
| プロンプト例 | `以下の情報に基づき、倫理審査申請書に記載すべき「利益相反（COI）に関する記述」を作成してください。COIがない場合と、ある場合の両方のパターンを記述してください。\n\n【研究情報】\n・研究資金源: 病院の自己資金\n・関与する企業: なし\n・研究者の役職: 病院職員` |
| AIの出力例 | 【利益相反がない場合の記述】\n本研究は、特定の企業や団体からの資金提供を受けておらず、研究者全員が本研究に関連する利益相反を有しないことをここに表明します。\n\n【利益相反がある場合の記述（例）】\n本研究の一部は、株式会社〇〇からの研究助成金（総額〇〇円）を受けて実施されます。研究責任者である〇〇は、同社の技術顧問を兼任しております。この利益相反は、当院の利益相反マネジメント委員会にて審査され、研究の公正性を確保するための以下の措置が講じられています。\n1. データ解析は、当該企業と関係のない第三者の研究員が独立して実施する。\n2. 研究結果の公表は、企業の意向に左右されず、研究者の判断に基づき行う。 |
| まとめ | COIの記述は、透明性の確保と研究の公正性を示すために重要です。AIは、規定のフォーマットに沿った正確な開示文案を生成できます。 |

---

## 応用編：審査対応と法規準拠の強化（2ステップ）

応用編では、倫理審査の最終段階である質疑応答への準備と、研究の法規準拠を徹底するための高度なAI活用法を紹介します。

### ステップ6：Q&Aシミュレーションと回答案作成

倫理審査委員会では、申請書の内容について厳しい質疑応答が行われます。AIに審査員の視点から質問を生成させ、回答案を準備することで、本番に備えます。

| 項目 | 詳細 |
| :--- | :--- |
| 目的 | 倫理審査委員会での質疑応答に備え、想定される質問と回答案を準備する。 |
| プロンプト例 | `作成した倫理審査申請書全体（これまでのステップの出力内容を統合）を入力し、「倫理審査委員会で想定される、最も厳しい質問を5つ挙げ、それぞれに対する簡潔かつ説得力のある回答案を作成してください。特に、AIの判断根拠の不透明性（ブラックボックス問題）に関する質問を含めてください。」` |
| AIの出力例 | 【想定質問と回答案】\n\nQ1. AIの判断根拠が不透明な場合（ブラックボックス問題）、患者や医師への説明責任をどのように果たしますか？\nA1. 本研究では、AIの判断根拠を可視化する技術（例: Grad-CAM）を併用し、医師がAIの推奨根拠を部分的に理解できるように努めます。また、最終的な診断は必ず医師が行い、AIの出力はあくまで参考情報として取り扱うことを徹底します。\n\nQ2. データセットのバイアスが、特定のマイノリティグループに対して不利益をもたらす可能性について、具体的な対策を教えてください。\nA2. データセットの属性分布を定期的に監視し、偏りが確認された場合は、追加データの収集または合成、あるいはバイアス是正アルゴリズム（例: Adversarial Debiasing）の適用を検討します。バイアス評価の結果は、研究報告書で開示します。\n\nQ3. 研究期間中に新たな倫理的課題が浮上した場合、どのような手続きで対応しますか？\nA3. 研究責任者は、新たな課題を速やかに倫理審査委員会事務局に報告し、委員会の指示に従って研究計画の変更申請を行います。研究者間で定期的なELSIレビュー会議を開催し、未然防止に努めます。\n\nQ4. 匿名化されたデータが、将来的に他のデータと照合されて再識別化されるリスクについて、どのように評価し、対応していますか？\nA4. 専門家による匿名化レベルの評価（k-匿名性など）を実施し、再識別化リスクが極めて低いことを確認しています。データは、当院のデータ管理規定に基づき、外部への持ち出しを厳禁とし、厳重なアクセス制御下に置かれます。\n\nQ5. 研究結果を公表する際、AIの限界や誤診の可能性について、どのように開示しますか？\nA5. 論文や学会発表においては、AIモデルの性能指標（感度、特異度、F1スコアなど）を正確に開示するとともに、モデルが誤診しやすい特定のサブグループや限界についても明確に記述します。 |
| まとめ | AIによるシミュレーションは、審査員の視点を内包した「仮想審査員」として機能し、研究者の準備不足を補完します。 |

### ステップ7：関連法規・ガイドラインの参照と整合性チェック

医療AI研究は、常に最新の法規やガイドライン（例：医療情報ガイドライン、個人情報保護法）に準拠している必要があります。AIに最新情報を参照させ、申請書との整合性をチェックさせます。

| 項目 | 詳細 |
| :--- | :--- |
| 目的 | 研究が関連する最新の法規やガイドラインに準拠しているかを確認し、申請書との整合性をチェックする。 |
| プロンプト例 | `以下の研究テーマと申請書ドラフト（データ管理計画、同意取得方法の記述）を入力し、「医療情報を取り扱うAI開発に関する最新の日本の法規・ガイドライン（例: 厚生労働省の医療情報ガイドライン、個人情報保護法）を挙げ、申請書の記述がそれらに準拠しているかを確認し、不足点や修正すべき点を指摘してください。` |
| AIの出力例 | 【準拠性チェック結果】\n\n1. 参照すべき主要な法規・ガイドライン\n- 個人情報保護法（2022年改正）: 特に「仮名加工情報」と「匿名加工情報」の定義と取り扱いに関する規定。\n- 医療情報システムの安全管理に関するガイドライン（第6.0版など最新版）: データの保管場所、アクセス制御、セキュリティ対策に関する要求事項。\n- 人を対象とする生命科学・医学系研究に関する倫理指針: 研究計画、同意取得、データ管理の全般的な枠組み。\n\n2. 申請書の記述の整合性チェック\n- データ管理計画: 申請書では「連結不可能匿名化」と記述されていますが、個人情報保護法上の「匿名加工情報」の定義と手続きに厳密に合致しているか、確認が必要です。不足点として、匿名加工情報の作成方法と第三者提供の有無に関する記述の明確化を推奨します。\n- 同意取得方法: 倫理指針に基づき、研究の不利益、撤回自由、データ利用の範囲について、患者が理解できる平易な言葉で説明する旨を追記すべきです。 |
| まとめ | AIは、膨大な法規・ガイドラインを参照し、申請書の記述との間の「抜け漏れ」を指摘する、高度なコンプライアンスチェック機能を発揮します。 |
