# 順伝播と逆伝播

## 🎯 このレッスンで学ぶこと

このレッスンを完了すると、入力から出力への計算フロー、誤差逆伝播法（Backpropagation）の原理、勾配の計算を理解できるようになります。

---

## 📖 セクション1: 順伝播（Forward Propagation）

### 順伝播とは

順伝播は、入力から出力への計算フローです。

**順伝播のプロセス**：
1. **入力層**：入力を受け取る
2. **隠れ層**：各層で計算を実行
3. **出力層**：最終的な出力を生成

### 計算の流れ

各層での計算：

**計算式**：
- **重み付き和**：入力と重みの積の和
- **活性化関数**：活性化関数を適用
- **出力**：次の層への入力

---

## 📖 セクション2: 誤差逆伝播法（Backpropagation）

### 誤差逆伝播法とは

誤差逆伝播法は、出力の誤差を逆方向に伝播させて、重みを更新する方法です。

**誤差逆伝播法のプロセス**：
1. **誤差の計算**：出力と正解の差を計算
2. **逆伝播**：誤差を逆方向に伝播
3. **重みの更新**：勾配に基づいて重みを更新

### 勾配の計算

勾配は、誤差を最小化する方向を示します。

**勾配の計算**：
- **偏微分**：各重みに対する偏微分
- **連鎖律**：連鎖律を使って勾配を計算
- **勾配降下法**：勾配に基づいて重みを更新

---

## 📖 セクション3: 学習のプロセス

### 学習のステップ

ニューラルネットワークの学習のステップ：

**学習のステップ**：
1. **順伝播**：入力から出力を計算
2. **誤差の計算**：出力と正解の差を計算
3. **逆伝播**：誤差を逆方向に伝播
4. **重みの更新**：勾配に基づいて重みを更新
5. **繰り返し**：ステップ1-4を繰り返す

### 収束

学習は、誤差が十分に小さくなるまで続けます。

**収束の判定**：
- **誤差の閾値**：誤差が閾値以下になったら終了
- **エポック数**：指定したエポック数に達したら終了
- **検証データ**：検証データでの性能が向上しなくなったら終了

---

## 💡 重要な洞察：学習の効率化

誤差逆伝播法により、効率的に学習できます。

**実践的な理解**：
- **勾配の計算**：勾配を効率的に計算
- **重みの更新**：勾配に基づいて重みを更新
- **収束**：適切な収束条件を設定

---

## 🎓 まとめ：順伝播と逆伝播を理解する

このレッスンでは、順伝播と逆伝播について学びました。

**重要なポイント**：

1. **順伝播**：入力から出力への計算フロー
2. **誤差逆伝播法**：誤差を逆方向に伝播させて重みを更新
3. **学習のプロセス**：順伝播、誤差計算、逆伝播、重み更新の繰り返し

### 次のステップ

次のレッスンでは、活性化関数とその役割について学びます。シグモイド、ReLU、tanhなどの活性化関数を理解します。

---

**更新日**: 2025年12月
